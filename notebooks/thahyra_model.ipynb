{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b67f7a0",
   "metadata": {},
   "source": [
    "# New baseline with 12?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48492f3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T15:12:47.884868Z",
     "iopub.status.busy": "2025-09-03T15:12:47.884173Z",
     "iopub.status.idle": "2025-09-03T15:12:47.890007Z",
     "shell.execute_reply": "2025-09-03T15:12:47.889226Z",
     "shell.execute_reply.started": "2025-09-03T15:12:47.884843Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mlt\n",
    "\n",
    "# Had to add this stuff to get notebook to find files, because it is not\n",
    "# located in the root folder\n",
    "ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(ROOT))\n",
    "\n",
    "from keras import Sequential, Input, layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.utils import load_img, img_to_array\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "from bee_tector.config import (\n",
    "    FULL_DATA_DIR,\n",
    "    IMAGE_SIZE,\n",
    "    CURATED_DATA_DIR,\n",
    "    MODELS_DIR\n",
    ")\n",
    "from bee_tector.plots import plot_history\n",
    "from bee_tector.data import (\n",
    "    load_datasets,\n",
    "    undersample_dataset,\n",
    "    load_selected_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "77e40809",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T15:12:56.510834Z",
     "iopub.status.busy": "2025-09-03T15:12:56.510545Z",
     "iopub.status.idle": "2025-09-03T15:13:00.377280Z",
     "shell.execute_reply": "2025-09-03T15:13:00.376784Z",
     "shell.execute_reply.started": "2025-09-03T15:12:56.510816Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3619 files belonging to 12 classes.\n",
      "Found 781 files belonging to 12 classes.\n",
      "Found 781 files belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds = load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "891d7f43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T15:13:04.026916Z",
     "iopub.status.busy": "2025-09-03T15:13:04.026358Z",
     "iopub.status.idle": "2025-09-03T15:13:04.054749Z",
     "shell.execute_reply": "2025-09-03T15:13:04.054199Z",
     "shell.execute_reply.started": "2025-09-03T15:13:04.026893Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def ensure_rgb(image, label):\n",
    "    if image.shape[-1] != 3:\n",
    "        image = tf.image.grayscale_to_rgb(image)\n",
    "    return image, label\n",
    "\n",
    "train_ds = train_ds.map(ensure_rgb)\n",
    "val_ds = val_ds.map(ensure_rgb)\n",
    "test_ds = test_ds.map(ensure_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ad461853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T15:52:50.315206Z",
     "iopub.status.busy": "2025-09-03T15:52:50.314955Z",
     "iopub.status.idle": "2025-09-03T15:52:50.321529Z",
     "shell.execute_reply": "2025-09-03T15:52:50.320827Z",
     "shell.execute_reply.started": "2025-09-03T15:52:50.315191Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def model_t(shape=(224, 224, 3), num_classes=12):\n",
    "\n",
    "    data_augmentation = Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.15),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.1),\n",
    "    layers.RandomTranslation(0.1, 0.1)\n",
    "        ], name=\"data_augmentation\")\n",
    "    # print(shape)\n",
    "    # loading a pretrainded model tf.keras.applications.EfficientNetB0\n",
    "    base_model = DenseNet121(\n",
    "    include_top=False, # Exclude the original ImageNet classification head\n",
    "    weights='imagenet', # Use pretrained weights from ImageNet\n",
    "    input_shape=(224, 224, 3))  # Input shape of your images\n",
    "            \n",
    "    # this freezes the model to Don't update the weights of the base model during training\n",
    "    # this way only the newly added layers  will be trained\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = Sequential(name=\"BeeClassifier\")\n",
    "\n",
    "    model.add(Input(shape=shape))\n",
    "    model.add(data_augmentation)\n",
    "    model.add(layers.Rescaling(1./255))  # RESCALE!\n",
    "    model.add(base_model)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    reg = regularizers.l2(1e-5)\n",
    "    model.add(layers.Dense(128, activation='relu', kernel_regularizer=reg))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4ef08606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T15:52:57.555165Z",
     "iopub.status.busy": "2025-09-03T15:52:57.554518Z",
     "iopub.status.idle": "2025-09-03T15:52:59.306531Z",
     "shell.execute_reply": "2025-09-03T15:52:59.305773Z",
     "shell.execute_reply.started": "2025-09-03T15:52:57.555141Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = model_t()\n",
    "model.get_layer('densenet121').trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "99fd9a8c-e37d-4bff-a90c-c9cdb6183609",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T15:13:29.585047Z",
     "iopub.status.busy": "2025-09-03T15:13:29.584772Z",
     "iopub.status.idle": "2025-09-03T15:13:29.594590Z",
     "shell.execute_reply": "2025-09-03T15:13:29.594084Z",
     "shell.execute_reply.started": "2025-09-03T15:13:29.585031Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "90e8fea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T15:13:33.114760Z",
     "iopub.status.busy": "2025-09-03T15:13:33.114472Z",
     "iopub.status.idle": "2025-09-03T15:37:19.276420Z",
     "shell.execute_reply": "2025-09-03T15:37:19.275679Z",
     "shell.execute_reply.started": "2025-09-03T15:13:33.114740Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 729ms/step - accuracy: 0.2010 - loss: 2.4134 - val_accuracy: 0.4635 - val_loss: 1.6733\n",
      "Epoch 2/1000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 666ms/step - accuracy: 0.5209 - loss: 1.5052 - val_accuracy: 0.5915 - val_loss: 1.2588\n",
      "Epoch 3/1000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 676ms/step - accuracy: 0.6180 - loss: 1.1774 - val_accuracy: 0.6159 - val_loss: 1.1923\n",
      "Epoch 4/1000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 680ms/step - accuracy: 0.6877 - loss: 0.9598 - val_accuracy: 0.6492 - val_loss: 1.1457\n",
      "Epoch 5/1000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 682ms/step - accuracy: 0.7447 - loss: 0.8039 - val_accuracy: 0.6645 - val_loss: 1.0792\n",
      "Epoch 6/1000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 681ms/step - accuracy: 0.7646 - loss: 0.7340 - val_accuracy: 0.6530 - val_loss: 1.1137\n",
      "Epoch 7/1000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 683ms/step - accuracy: 0.8030 - loss: 0.6340 - val_accuracy: 0.6773 - val_loss: 1.0423\n",
      "Epoch 8/1000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 682ms/step - accuracy: 0.8385 - loss: 0.4917 - val_accuracy: 0.6415 - val_loss: 1.2471\n",
      "Epoch 9/1000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 682ms/step - accuracy: 0.8394 - loss: 0.4886 - val_accuracy: 0.6556 - val_loss: 1.1535\n",
      "Epoch 10/1000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 682ms/step - accuracy: 0.8620 - loss: 0.4222 - val_accuracy: 0.6965 - val_loss: 1.1302\n",
      "Epoch 11/1000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 682ms/step - accuracy: 0.8714 - loss: 0.4283 - val_accuracy: 0.6748 - val_loss: 1.1955\n",
      "Epoch 12/1000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 682ms/step - accuracy: 0.8982 - loss: 0.3110 - val_accuracy: 0.6965 - val_loss: 1.1333\n",
      "Epoch 13/1000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 681ms/step - accuracy: 0.8900 - loss: 0.3397 - val_accuracy: 0.6684 - val_loss: 1.1715\n",
      "Epoch 14/1000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 682ms/step - accuracy: 0.9020 - loss: 0.3082 - val_accuracy: 0.6889 - val_loss: 1.1805\n",
      "Epoch 15/1000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 681ms/step - accuracy: 0.9143 - loss: 0.2708 - val_accuracy: 0.7042 - val_loss: 1.1109\n",
      "Epoch 16/1000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 682ms/step - accuracy: 0.9340 - loss: 0.2035 - val_accuracy: 0.6991 - val_loss: 1.1572\n",
      "Epoch 17/1000\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 681ms/step - accuracy: 0.9383 - loss: 0.2078 - val_accuracy: 0.6556 - val_loss: 1.4609\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=1000,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[es],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bf25187e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T15:37:42.759708Z",
     "iopub.status.busy": "2025-09-03T15:37:42.758977Z",
     "iopub.status.idle": "2025-09-03T15:37:49.440474Z",
     "shell.execute_reply": "2025-09-03T15:37:49.439954Z",
     "shell.execute_reply.started": "2025-09-03T15:37:42.759681Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.7434 - loss: 0.8236\n",
      "Validation loss: 1.0423, Validation accuracy: 0.6773\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.7781 - loss: 0.7104\n",
      "Test loss: 0.9593, Test accuracy: 0.7068\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(val_ds)\n",
    "print(f\"Validation loss: {val_loss:.4f}, Validation accuracy: {val_acc:.4f}\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c90512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fb2058f",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8195727,
     "sourceId": 12950525,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
